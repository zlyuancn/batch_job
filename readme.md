



---

# 如何实现的

## 任务如何启动

### 定时启动

如果没有超过启动器上限, 则扫描非本地执行的运行中任务. 并对于运行中的任务触发启动创建一个任务启动器

```mermaid
sequenceDiagram
participant a as 定时器
participant b as 服务
participant c as redis
participant d as mysql

opt 定时任务启动
a ->> b: 触发

b -->> d: 获取正在运行的任务列表
b -->> b: 获取节点的任务数上限
b ->> c: 将当前节点信息写入到 zset 表中. score表示当前秒级时间戳
b -->> c: 获取最近5分钟的节点数
b -->> b: 将任务数平分给节点得出上限, 并与配置的上限取其小值为实际节点任务数上限

loop 遍历每一条任务
  alt 当前已达到节点任务数上限
    b -->> b: 结束
  end
  b ->> b: 创建启动器
end
end
```

### 接口调用启动

直接触发启动创建一个任务启动器

```mermaid
sequenceDiagram
participant api
participant b as 服务

opt api启动
api ->> b: 触发
b ->> b: 创建启动器
b ->> api: ok
end
```

### 启动器上限

一个服务同时只能执行n个任务, 这是根据配置最大上限以及节点数决定的. 比如当前有10个任务, 有3个服务节点. 配置每节点最多允许执行5个任务. 则每个节点实际最多允许运行4个. 这是将任务数平分给节点后(进一法). 与配置的上限对比去小值

节点每x分钟向redis的一个zset注册. 提供注册时间和节点id. 并获取最近x分钟注册的节点数. 这个数被认为是服务节点数.

## 启动器

启动器创建后会获取任务执行锁. 锁ttl一般为5分钟. 如果获取成功, 则每隔 ttl*1/3 时间为锁续期.

启动器成功创建时会增加当前节点的任务执行数

```mermaid
sequenceDiagram
participant b as 服务
participant c as redis
participant d as mysql
participant f as 业务

alt 业务层注册了启动前回调&&不是由业务创建的启动器
  b ->> c: 写入启动器回调锁. 锁ttl约30分钟. 这是有部分业务在启动前可能会下载数据. 需要给充足的下载时间
  b ->> f: 启动前回调
  f -->> f: 数据检查, 数据下载, 缓存创建等
  b ->> b: 结束
end

b ->> c: 写入任务锁. 锁ttl约为10分钟
b ->> c: defer 解除任务锁

b ->> b: 增加节点的已执行任务数
par 协程
  loop 间隔2分钟
   b -->> c: 对锁续期
  end
end

alt 任务进度已达标
  b ->> d: 更新进度和任务状态和错误数
end

b ->> c: 将当前进度写入到缓存中

b ->> b: 根据当前进度创建滑动窗口, 窗口大小为批次速率的10倍

loop 滑动窗口还有任务未执行完毕
  b ->> b: 获取限速令牌
  
  b -->> c: 获取停止flag(1分钟触发一次)
  alt 收到停止信号
    b ->> d: 更新进度和任务状态和错误数
  end
  
  par
    b -->> f: 处理回调
    f ->> f: 根据传入数据索引号处理数据
    alt 错误累计
      b ->> b: 获取错误累计令牌, 如果拿不到则表示本次无法继续执行了. 应该退出这个过程
    end
    b ->> b: 更新滑动窗口中索引数据号为已完成. 如果这个索引号之前的任务都完成. 则更新当前偏移值和最大区块值(滑动窗口)
  end
end
b ->> b: 等待区块任务执行完毕
b ->> c: 更新进度
```

## 任务处理流程

### 管理端控制

```mermaid
sequenceDiagram
participant a as 管理端
participant b as 批量工具
participant c as mq
participant d as mysql
participant e as redis
participant f as 业务

opt 创建批量任务
a ->> b: 创建批量任务
b -->> e: 生成任务单号
b ->> f: 创建回调
f -->> f: 数据检查等
b ->> d: 写入任务信息到数据库(包含用户列表或者用户url)
b ->> a: ok
end

opt 启动批量任务
a ->> b: 启动批量任务
b -->> e: 获取操作锁, defer 自动解锁
b -->> d: 获取任务信息. 对于运行中的任务, 需要从redis获取进度并从redis获取失败数
alt 对于非 已创建/已停止 状态
  b ->> a: err
end
b ->> d: 更新状态为运行中/等待业务运行
par
  b -->> b: defer 如果流程失败则更新状态为已停止
  b ->> e: 删除停止flag
  b ->> b: 创建启动器
end
b ->> a: ok
end

opt 暂停/停止批量任务
  a->>b: 停止任务
  b -->> e: 获取操作锁, defer 自动解锁
  alt 任务状态不是 运行中/等待业务主动启动
     b -->> a: err
  end
  b -->> e: 获取停止信号
  alt 已经写入过停止信号
     b ->> a: ok
  end
  b->>c: 写入停止信号, 带有效期7天
  b->>e: 更新任务状态为正在停止
  b->>a: ok
end
```

### 业务控制

```mermaid
sequenceDiagram
participant f as 业务层
participant b as 批量工具
participant d as mysql
participant e as redis

opt 业务启动批量任务
f ->> b: 业务启动批量任务
b -->> d: 获取任务信息
alt 对于非 等待业务主动启动
  b ->> f: err
end

par 
  b ->> e: 获取停止flag
  alt 停止标记
    b ->> b: 结束
  end

  b ->> d: 更新状态为运行中
  b ->> b: 创建启动器
end

b ->> f: ok
end

opt 业务停止. 一般为业务判断任务无法继续推进的时候
  f ->> b: 停止任务
  b ->> e: 写入停止标记
  b ->> f: ok
end

opt 更新业务数据. 只有在等待业务主动启动状态时或者串行化(rate=1)的任务可以使用
  f ->> b: 更新业务数据
  b ->> d: 获取业务数据信息
  alt 对于非 等待业务主动启动 状态或者非串行化(rate=1)的任务
    b ->> f: err
  end
  b ->> d: 更新数据
  b ->> f: ok
end

opt 写入数据日志
  f ->> b: 写入数据日志
  b ->> d: 写入数据日志
  b ->> f: ok
end
```

## 如何并行执行任务数据处理

### 仅储存任务进度. 之后的数据通过滑动窗口取出批次数据并行扔给业务处理, 滑动窗口起点表示之前的所有数据都处理完毕, 定时同步滑动窗口进度

优点, 对于进度的储存占用空间忽略不计, 更新io耗时降低为O(1). 且进度同步是间隔的而不是每次更新就同步. 进一步降低io消耗. 业务的并行执行速度得到最大的发挥. 一批次中的一条任务执行完毕后会立即进行下一条处理, 业务节点的性能得到大幅释放, 且消费速率曲线稳定. 速率由批量任务平台精确控制, 业务层无需考虑并行/速率的实现, 只需要考虑对单条数据的处理.

缺点. 滑动窗口一般为业务并行处理速率的n倍, 一旦批量任务平台执行该任务的节点异常丢失节点. 最复杂的情况下需要重跑整个滑动窗口长度的数据量.



### 一些被弃用的方案

#### 仅储存进度. 串行化执行, 让业务控制并发量. 业务主动告知平台本次处理完成了多少任务量

优点. 业务对进度和并发自主可控

缺点. 业务想要并行执行需要自行实现, 处理速率也需要业务实现, 业务需要主动报告, 平台对任务的速率无法控制.

#### 将每个数据扔给mq, 让mq来并行消费调用业务处理

增加了一个新的mq系统. 业务会变得更加复杂. 且, 数据扔给mq会导致数据膨胀, 比如将索引1的数据扔给mq, 除了数据本身之外, mq的系统会为这个数据增加一些mq系统独有的内容来支撑mq运行. 而且增加了对mq的io消耗. 如果数据量非常大则产生非常高的mq系统费用.

#### 使用bit位来表示一条数据是否完成, 将bit数据放入redis中

这里通过扫描bit位拿到未完成的一批次数据, 循环产生协程调用业务处理. 处理完成的任务更新bit位.

缺点. 对于100亿数据. 会占用 1.16GB的bit数据来表示. 对redis来说比较高了. 且扫描redis中的为0或1的bit位耗时为O(N)

#### 将bit位存放在服务本地内存, 定时刷新到redis

缺点. 100亿数据每次同步bit位会写入1.16GB数据, 对redis负担巨大

#### 仅储存任务进度, 将一段数据作为一批次数据, 只有这一批次数据全部执行完毕才会更新进度

优点, 对于进度的储存占用空间忽略不计, 更新io耗时降低为O(1). 将这一批次的数据全部协程扔给业务处理. 如果有错误需要重试这些数据直到这批次数据全部处理完成后才会开始下一批次的处理. 一批次处理完成后就更新任务进度

可以考虑间隔同步进度而不是试试同步进度. 这样可以进一步降低进度同步消耗io, 即使同步失败, 只有节点本身异常导致进度丢失才会真的丢失最新进度.

缺点. 

一批次中的数据不一定是同时完成的, 比如业务具备100条的并行处理速度, 当其中50条完成了. 需要等待另外50条也完成才会开始下一批次的处理. 浪费至少一半的节点资源.

一批次中部分数据处理失败虽然会重试, 但是会降低处理速率. 比如业务具备100条的并行处理速度. 我们扔给业务100条数据. 其中有3条失败, 则我们下一次将这3条错误数据扔给业务重试. 此时业务只能并行执行3条. 浪费了97%的资源.


